{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12715ccc",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60447590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "keras = tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3e712f",
   "metadata": {},
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74e344c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>You won't be disappointed.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text  sentiment\n",
       "1318  You won't be disappointed.          1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/login/Documents/Machine_learning/Datasets/reviews/reviews.csv\"\n",
    "dataset = pd.read_csv(data_path, index_col = 'Unnamed: 0')\n",
    "dataset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bff70aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = dataset['text'].tolist()\n",
    "labels = dataset['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2615144",
   "metadata": {},
   "source": [
    "### Create a subwords dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4a70258",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    sentences, vocab_size, max_subword_length = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c23d1470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have to jiggle the plug to get it to line up right to get decent volume.\n",
      "[4, 31, 6, 849, 162, 450, 12, 1, 600, 438, 775, 6, 175, 14, 6, 55, 213, 159, 474, 775, 6, 175, 614, 380, 295, 148, 72, 789]\n",
      "I \n",
      "have \n",
      "to \n",
      "j\n",
      "ig\n",
      "gl\n",
      "e \n",
      "the \n",
      "pl\n",
      "ug\n",
      " \n",
      "to \n",
      "get \n",
      "it \n",
      "to \n",
      "li\n",
      "ne \n",
      "up \n",
      "right\n",
      " \n",
      "to \n",
      "get \n",
      "dec\n",
      "ent \n",
      "vo\n",
      "lu\n",
      "me\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Check tokenizer works properly\n",
    "num = 5\n",
    "print(sentences[5])\n",
    "\n",
    "encoded = tokenizer.encode(sentences[num])\n",
    "print(encoded)\n",
    "\n",
    "for i in encoded:\n",
    "    print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f71659a",
   "metadata": {},
   "source": [
    "### Replace sentence data with encoded subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87b59aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    sentences[i] = tokenizer.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c33ba60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[625, 677, 626, 274, 380, 633, 148, 844, 789]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1f184",
   "metadata": {},
   "source": [
    "### Final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09084061",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "\n",
    "sentences_padded = pad_sequences(sentences, maxlen = max_length,\n",
    "                                truncating = trunc_type, padding = padding_type)\n",
    "\n",
    "train_size = int(len(sentences_padded) * .8)\n",
    "\n",
    "train_sentences = sentences_padded[:train_size]\n",
    "test_sentences = sentences_padded[train_size:]\n",
    "train_labels = labels[:train_size]\n",
    "test_labels = labels[train_size:]\n",
    "\n",
    "train_labels_final = np.array(train_labels)\n",
    "test_labels_final = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78a2e981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d5ba4",
   "metadata": {},
   "source": [
    "### Train a sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ce50c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 16)            16000     \n",
      "                                                                 \n",
      " global_average_pooling1d_2  (None, 16)                0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16109 (62.93 KB)\n",
      "Trainable params: 16109 (62.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    keras.layers.GlobalAveragePooling1D(),\n",
    "    keras.layers.Dense(6, activation = 'relu'),\n",
    "    keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9d4259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 2s 7ms/step - loss: 0.6913 - accuracy: 0.5229 - val_loss: 0.6979 - val_accuracy: 0.4110\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.5336 - val_loss: 0.7001 - val_accuracy: 0.4211\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.5430 - val_loss: 0.6979 - val_accuracy: 0.4461\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5650 - val_loss: 0.6927 - val_accuracy: 0.4887\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.6146 - val_loss: 0.6845 - val_accuracy: 0.5163\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.6365 - val_loss: 0.6738 - val_accuracy: 0.5414\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.7056 - val_loss: 0.6584 - val_accuracy: 0.5990\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.7320 - val_loss: 0.6330 - val_accuracy: 0.7093\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7966 - val_loss: 0.6187 - val_accuracy: 0.6892\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8067 - val_loss: 0.5978 - val_accuracy: 0.7093\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.8374 - val_loss: 0.5855 - val_accuracy: 0.6917\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.8311 - val_loss: 0.5489 - val_accuracy: 0.7619\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.8537 - val_loss: 0.5529 - val_accuracy: 0.7343\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8625 - val_loss: 0.5248 - val_accuracy: 0.7419\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3992 - accuracy: 0.8619 - val_loss: 0.5176 - val_accuracy: 0.7469\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3752 - accuracy: 0.8707 - val_loss: 0.4999 - val_accuracy: 0.7719\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8801 - val_loss: 0.5138 - val_accuracy: 0.7494\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8839 - val_loss: 0.5112 - val_accuracy: 0.7519\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8839 - val_loss: 0.5058 - val_accuracy: 0.7544\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.8901 - val_loss: 0.5020 - val_accuracy: 0.7494\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.9027 - val_loss: 0.5143 - val_accuracy: 0.7569\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2812 - accuracy: 0.9008 - val_loss: 0.4996 - val_accuracy: 0.7494\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.9058 - val_loss: 0.5068 - val_accuracy: 0.7544\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.9140 - val_loss: 0.5175 - val_accuracy: 0.7519\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.9140 - val_loss: 0.5436 - val_accuracy: 0.7444\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9203 - val_loss: 0.5087 - val_accuracy: 0.7519\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 0.9234 - val_loss: 0.5196 - val_accuracy: 0.7544\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9266 - val_loss: 0.5313 - val_accuracy: 0.7519\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9253 - val_loss: 0.5399 - val_accuracy: 0.7444\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9328 - val_loss: 0.5462 - val_accuracy: 0.7368\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "model.compile(loss = keras.losses.BinaryCrossentropy(),\n",
    "              optimizer = keras.optimizers.Adam(),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_sentences, train_labels_final, epochs = EPOCHS,\n",
    "                   validation_data = (test_sentences, test_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4d7c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Virtual Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
