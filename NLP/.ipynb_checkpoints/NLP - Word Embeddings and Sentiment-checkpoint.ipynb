{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29431478",
   "metadata": {},
   "source": [
    "### SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81304537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80842395",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5121ea23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>Best headset ever!!!.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1671</td>\n",
       "      <td>Service was slow and not attentive.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                 text  sentiment\n",
       "887          887                Best headset ever!!!.          1\n",
       "1671        1671  Service was slow and not attentive.          0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '/home/login/Documents/Machine_learning/Datasets/reviews/reviews.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b49cb0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>VERY comfortable.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Good service very clean and inexpensive to boot!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "330                                  VERY comfortable.          1\n",
       "1255  Good service very clean and inexpensive to boot!          1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318daf1",
   "metadata": {},
   "source": [
    "#### Randomize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86e698a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1195, 1645, 1858, ...,  793, 1265,  685])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72c946f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>The nano stated it.My son was dissapointed.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>So anyone near you will hear part of your conv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>However BT headsets are currently not good for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>Spend your money and time some place else.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Comfort for our whole family.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "757         The nano stated it.My son was dissapointed.          0\n",
       "706   So anyone near you will hear part of your conv...          0\n",
       "637   However BT headsets are currently not good for...          0\n",
       "1983         Spend your money and time some place else.          0\n",
       "279                       Comfort for our whole family.          1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reindex(np.random.permutation(data.index))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4bca176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text'].tolist()\n",
    "labels = data['sentiment'].tolist()\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16154ca",
   "metadata": {},
   "source": [
    "#### Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "062cdeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1593\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(labels) * 0.8)\n",
    "print(f\"Train size: {train_size}\")\n",
    "\n",
    "train_sentences = sentences[:train_size]\n",
    "test_sentences = sentences[train_size:]\n",
    "train_labels = labels[:train_size]\n",
    "test_labels = labels[train_size:]\n",
    "\n",
    "# Make labels into numpy arrays for use with network later\n",
    "train_labels_final = np.array(train_labels)\n",
    "test_labels_final = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db5ffc",
   "metadata": {},
   "source": [
    "### Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3712a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 35  64 157 ...   0   0   0]\n",
      " [  4 136  32 ...   0   0   0]\n",
      " [  4  63 175 ...   0   0   0]\n",
      " ...\n",
      " [ 35  23   1 ...   0   0   0]\n",
      " [188   0   0 ...   0   0   0]\n",
      " [  1 202  13 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 2\n",
    "max_length = 100\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences, padding = padding_type, \n",
    "                            truncating = trunc_type, maxlen = max_length)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_padded = pad_sequences(test_sequences, truncating = trunc_type,\n",
    "                           maxlen = max_length, padding = padding_type)\n",
    "print(test_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdb943e",
   "metadata": {},
   "source": [
    "### Review a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4a5d6800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "however bt headsets are <OOV> not good for real time games like first person <OOV> since the audio <OOV> <OOV> me up ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "However BT headsets are currently not good for real time games like first-person shooters since the audio delay messes me up.\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "'''<oov>:1 becomes 1: <oov>'''\n",
    "\n",
    "def decode_review(text):\n",
    "    \"\"\"Loops through the text and returns the value at given index.? is returned\n",
    "    when 0 is found since its not in the reversed dictionary\"\"\"\n",
    "    return \" \".join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(train_padded[2]))\n",
    "print(train_sentences[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759aa960",
   "metadata": {},
   "source": [
    "### Train a Basic Sentiment Model with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c62967a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 2)            2000      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1206      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3213 (12.55 KB)\n",
      "Trainable params: 3213 (12.55 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f87afb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 1s 6ms/step - loss: 0.6936 - accuracy: 0.4953 - val_loss: 0.6930 - val_accuracy: 0.5013\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5650 - val_loss: 0.6925 - val_accuracy: 0.5213\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.6114 - val_loss: 0.6910 - val_accuracy: 0.5739\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6535 - val_loss: 0.6876 - val_accuracy: 0.5840\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6729 - accuracy: 0.6880 - val_loss: 0.6814 - val_accuracy: 0.6115\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7558 - val_loss: 0.6694 - val_accuracy: 0.6115\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6161 - accuracy: 0.7690 - val_loss: 0.6487 - val_accuracy: 0.6316\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.8067 - val_loss: 0.6222 - val_accuracy: 0.6316\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.8236 - val_loss: 0.5970 - val_accuracy: 0.6817\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8562 - val_loss: 0.5694 - val_accuracy: 0.6792\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8726 - val_loss: 0.5472 - val_accuracy: 0.7093\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8901 - val_loss: 0.5313 - val_accuracy: 0.7218\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.9021 - val_loss: 0.5145 - val_accuracy: 0.7393\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.9165 - val_loss: 0.5082 - val_accuracy: 0.7343\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.9228 - val_loss: 0.5210 - val_accuracy: 0.7444\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9316 - val_loss: 0.4955 - val_accuracy: 0.7569\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9429 - val_loss: 0.4918 - val_accuracy: 0.7519\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9510 - val_loss: 0.4924 - val_accuracy: 0.7569\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1684 - accuracy: 0.9579 - val_loss: 0.4983 - val_accuracy: 0.7569\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9623 - val_loss: 0.4963 - val_accuracy: 0.7519\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9680 - val_loss: 0.5122 - val_accuracy: 0.7569\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1321 - accuracy: 0.9705 - val_loss: 0.5099 - val_accuracy: 0.7644\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.1209 - accuracy: 0.9724 - val_loss: 0.5305 - val_accuracy: 0.7594\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9749 - val_loss: 0.5350 - val_accuracy: 0.7594\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9755 - val_loss: 0.5252 - val_accuracy: 0.7619\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9780 - val_loss: 0.5369 - val_accuracy: 0.7694\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9787 - val_loss: 0.5443 - val_accuracy: 0.7694\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9812 - val_loss: 0.5562 - val_accuracy: 0.7669\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9818 - val_loss: 0.5595 - val_accuracy: 0.7669\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9812 - val_loss: 0.5728 - val_accuracy: 0.7644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fdca0d13850>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "model.fit(train_padded, train_labels_final, epochs = EPOCHS, validation_data = (test_padded, test_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e39a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Virtual Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
