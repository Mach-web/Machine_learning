{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e244630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "#create a yolo model from scratch\n",
    "model = YOLO(\"yolov8n.yaml\")\n",
    "\n",
    "# load a pretrained yolo model\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2847a0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train3', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train3', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\mkand\\Documents\\YOLO\\datasets\\coco8\\labels\\train.cache... 4 images, 0 backgrounds, 0 corrupt: \u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\mkand\\Documents\\YOLO\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.412      2.814      1.755         22        640: 100%|██████████| 1/1 [00:06<00:00,  6.79\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.613      0.883      0.888      0.616\n",
      "                   all          4         17      0.613      0.883      0.888      0.616\n",
      "                   all          4         17      0.613      0.883      0.888      0.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.249       2.62      1.441         23        640: 100%|██████████| 1/1 [00:04<00:00,  4.16\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.598      0.896      0.888      0.618\n",
      "                   all          4         17      0.598      0.896      0.888      0.618\n",
      "                   all          4         17      0.598      0.896      0.888      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.142       4.22      1.495         16        640: 100%|██████████| 1/1 [00:03<00:00,  3.61\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17       0.58      0.833      0.874      0.613\n",
      "                   all          4         17       0.58      0.833      0.874      0.613\n",
      "                   all          4         17       0.58      0.833      0.874      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.017 hours.\n",
      "\n",
      "3 epochs completed in 0.017 hours.\n",
      "\n",
      "3 epochs completed in 0.017 hours.\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.599      0.898      0.888      0.618\n",
      "                   all          4         17      0.599      0.898      0.888      0.618\n",
      "                   all          4         17      0.599      0.898      0.888      0.618\n",
      "                person          3         10      0.647        0.5       0.52       0.29\n",
      "                person          3         10      0.647        0.5       0.52       0.29\n",
      "                person          3         10      0.647        0.5       0.52       0.29\n",
      "                   dog          1          1      0.315          1      0.995      0.597\n",
      "                   dog          1          1      0.315          1      0.995      0.597\n",
      "                   dog          1          1      0.315          1      0.995      0.597\n",
      "                 horse          1          2      0.689          1      0.995      0.598\n",
      "                 horse          1          2      0.689          1      0.995      0.598\n",
      "                 horse          1          2      0.689          1      0.995      0.598\n",
      "              elephant          1          2      0.629      0.887      0.828      0.332\n",
      "              elephant          1          2      0.629      0.887      0.828      0.332\n",
      "              elephant          1          2      0.629      0.887      0.828      0.332\n",
      "              umbrella          1          1      0.539          1      0.995      0.995\n",
      "              umbrella          1          1      0.539          1      0.995      0.995\n",
      "              umbrella          1          1      0.539          1      0.995      0.995\n",
      "          potted plant          1          1      0.774          1      0.995      0.895\n",
      "          potted plant          1          1      0.774          1      0.995      0.895\n",
      "          potted plant          1          1      0.774          1      0.995      0.895\n",
      "Speed: 3.9ms preprocess, 289.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Speed: 3.9ms preprocess, 289.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Speed: 3.9ms preprocess, 289.9ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# train model using coco.yaml\n",
    "results = model.train(data=\"coco8.yaml\", epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79518ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\mkand\\Documents\\YOLO\\datasets\\coco8\\labels\\val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.599      0.898      0.888      0.618\n",
      "                   all          4         17      0.599      0.898      0.888      0.618\n",
      "                   all          4         17      0.599      0.898      0.888      0.618\n",
      "                person          3         10      0.647        0.5       0.52       0.29\n",
      "                person          3         10      0.647        0.5       0.52       0.29\n",
      "                person          3         10      0.647        0.5       0.52       0.29\n",
      "                   dog          1          1      0.315          1      0.995      0.597\n",
      "                   dog          1          1      0.315          1      0.995      0.597\n",
      "                   dog          1          1      0.315          1      0.995      0.597\n",
      "                 horse          1          2      0.689          1      0.995      0.598\n",
      "                 horse          1          2      0.689          1      0.995      0.598\n",
      "                 horse          1          2      0.689          1      0.995      0.598\n",
      "              elephant          1          2      0.629      0.887      0.828      0.332\n",
      "              elephant          1          2      0.629      0.887      0.828      0.332\n",
      "              elephant          1          2      0.629      0.887      0.828      0.332\n",
      "              umbrella          1          1      0.539          1      0.995      0.995\n",
      "              umbrella          1          1      0.539          1      0.995      0.995\n",
      "              umbrella          1          1      0.539          1      0.995      0.995\n",
      "          potted plant          1          1      0.774          1      0.995      0.895\n",
      "          potted plant          1          1      0.774          1      0.995      0.895\n",
      "          potted plant          1          1      0.774          1      0.995      0.895\n",
      "Speed: 4.7ms preprocess, 324.5ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Speed: 4.7ms preprocess, 324.5ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Speed: 4.7ms preprocess, 324.5ms inference, 0.0ms loss, 7.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train32\u001b[0m\n",
      "Results saved to \u001b[1mruns\\detect\\train32\u001b[0m\n",
      "Results saved to \u001b[1mruns\\detect\\train32\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# evaluate model performace\n",
    "results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10585801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\mkand\\Documents\\Machine_learning\\YOLO\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 289.0ms\n",
      "image 1/1 C:\\Users\\mkand\\Documents\\Machine_learning\\YOLO\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 289.0ms\n",
      "image 1/1 C:\\Users\\mkand\\Documents\\Machine_learning\\YOLO\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 289.0ms\n",
      "Speed: 6.2ms preprocess, 289.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Speed: 6.2ms preprocess, 289.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Speed: 6.2ms preprocess, 289.0ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "[ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[122, 148, 172],\n",
      "        [120, 146, 170],\n",
      "        [125, 153, 177],\n",
      "        ...,\n",
      "        [157, 170, 184],\n",
      "        [158, 171, 185],\n",
      "        [158, 171, 185]],\n",
      "\n",
      "       [[127, 153, 177],\n",
      "        [124, 150, 174],\n",
      "        [127, 155, 179],\n",
      "        ...,\n",
      "        [158, 171, 185],\n",
      "        [159, 172, 186],\n",
      "        [159, 172, 186]],\n",
      "\n",
      "       [[128, 154, 178],\n",
      "        [126, 152, 176],\n",
      "        [126, 154, 178],\n",
      "        ...,\n",
      "        [158, 171, 185],\n",
      "        [158, 171, 185],\n",
      "        [158, 171, 185]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[185, 185, 191],\n",
      "        [182, 182, 188],\n",
      "        [179, 179, 185],\n",
      "        ...,\n",
      "        [114, 107, 112],\n",
      "        [115, 105, 111],\n",
      "        [116, 106, 112]],\n",
      "\n",
      "       [[157, 157, 163],\n",
      "        [180, 180, 186],\n",
      "        [185, 186, 190],\n",
      "        ...,\n",
      "        [107,  97, 103],\n",
      "        [102,  92,  98],\n",
      "        [108,  98, 104]],\n",
      "\n",
      "       [[112, 112, 118],\n",
      "        [160, 160, 166],\n",
      "        [169, 170, 174],\n",
      "        ...,\n",
      "        [ 99,  89,  95],\n",
      "        [ 96,  86,  92],\n",
      "        [102,  92,  98]]], dtype=uint8)\n",
      "orig_shape: (1080, 810)\n",
      "path: 'C:\\\\Users\\\\mkand\\\\Documents\\\\Machine_learning\\\\YOLO\\\\bus.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\train33'\n",
      "speed: {'preprocess': 6.160736083984375, 'inference': 288.9590263366699, 'postprocess': 4.95600700378418}]\n"
     ]
    }
   ],
   "source": [
    "# perform object detection on object\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803569e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "Ultralytics YOLOv8.2.38  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i5-8350U 1.70GHz)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train3\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train3\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train3\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mkand\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mkand\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (3.20.3)\n",
      "Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 14.4/14.4 MB 1.6 MB/s eta 0:00:008\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.16.1\n",
      "\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mkand\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mkand\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (3.20.3)\n",
      "Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 14.4/14.4 MB 1.6 MB/s eta 0:00:008\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.16.1\n",
      "\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\mkand\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\mkand\\anaconda3\\lib\\site-packages (from onnx>=1.12.0) (3.20.3)\n",
      "Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 14.4/14.4 MB 1.6 MB/s eta 0:00:008\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.16.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  37.7s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  37.7s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  37.7s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export failure  37.7s: No module named 'onnx'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export failure  37.7s: No module named 'onnx'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export failure  37.7s: No module named 'onnx'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Export the model to ONNX format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m success \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m success\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Machine_learning\\Lib\\site-packages\\ultralytics\\engine\\model.py:602\u001b[0m, in \u001b[0;36mModel.export\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    600\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[0;32m    601\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Exporter(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Machine_learning\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:306\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    304\u001b[0m     f[\u001b[38;5;241m1\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_engine()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m onnx:  \u001b[38;5;66;03m# ONNX\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     f[\u001b[38;5;241m2\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_onnx()\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xml:  \u001b[38;5;66;03m# OpenVINO\u001b[39;00m\n\u001b[0;32m    308\u001b[0m     f[\u001b[38;5;241m3\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_openvino()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Machine_learning\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:142\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    141\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export failure ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Machine_learning\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:137\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[1;32m--> 137\u001b[0m         f, model \u001b[38;5;241m=\u001b[39m inner_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f, model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Machine_learning\\Lib\\site-packages\\ultralytics\\engine\\exporter.py:393\u001b[0m, in \u001b[0;36mExporter.export_onnx\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    391\u001b[0m     requirements \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxslim==0.1.28\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnxruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m    392\u001b[0m check_requirements(requirements)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    395\u001b[0m opset_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mopset \u001b[38;5;129;01mor\u001b[39;00m get_latest_opset()\n\u001b[0;32m    396\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m starting export with onnx \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m opset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopset_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnx'"
     ]
    }
   ],
   "source": [
    "# Export the model to ONNX format\n",
    "success = model.export(format=\"onnx\")\n",
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a18d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
