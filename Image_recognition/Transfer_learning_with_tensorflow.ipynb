{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8491fa",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfac45c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe27a853b50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-nightly-gpu/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe27a695310>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-nightly-gpu/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe27a69c090>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-nightly-gpu/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe27a6b9390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-nightly-gpu/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fe27a6ba050>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tf-nightly-gpu/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tf-nightly-gpu==1.14.1-dev20190409 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tf-nightly-gpu==1.14.1-dev20190409\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f944d15c950>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow-hub/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f944b8aa790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow-hub/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f944b89b7d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow-hub/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f944b87b310>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow-hub/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f944b8a9010>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/tensorflow-hub/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_hub==0.4.0 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow_hub==0.4.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install 'tf-nightly-gpu==1.14.1-dev20190409'\n",
    "!pip install 'tensorflow_hub==0.4.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920d37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c49ee76",
   "metadata": {},
   "source": [
    "## Part 1: Use TensorFlow Hub MobileNet for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4378692",
   "metadata": {},
   "source": [
    "#### Download the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45e93cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m classifier_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m IMG_SHAPE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m224\u001b[39m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mhub\u001b[49m\u001b[38;5;241m.\u001b[39mKerasLayer(classifier_url, input_shape \u001b[38;5;241m=\u001b[39m (IMG_SHAPE, IMG_SHAPE, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      7\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hub' is not defined"
     ]
    }
   ],
   "source": [
    "classifier_url = \"\"\n",
    "\n",
    "IMG_SHAPE = 224\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(classifier_url, input_shape = (IMG_SHAPE, IMG_SHAPE, 3))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27e6ab",
   "metadata": {},
   "source": [
    "### Run it on single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d0ecef7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL.image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m grace_hopper \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PIL.image'"
     ]
    }
   ],
   "source": [
    "import PIL.image as Image\n",
    "import numpy as np\n",
    "\n",
    "grace_hopper = tf.keras.utils.get_file('image.jpg', )\n",
    "grace_hopper = Image.open(grace_hopper).resize((IMG_SHAPE, IMG_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72602769",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grace_hopper \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(grace_hopper)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m\n\u001b[1;32m      2\u001b[0m grace_hopper\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "grace_hopper = np.array(grace_hopper)/255.0\n",
    "grace_hopper.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a44e4d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(grace_hopper[np\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "result = model.predict(grace_hopper[np.newaxis, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e5f957b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39margmax(result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m predicted_class\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_class = np.argmax(result = 0, axis = -1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc9924",
   "metadata": {},
   "source": [
    "### Decode the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef3e763a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please specify the \"origin\" argument (URL of the file to download).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels_path \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m imagenet_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mopen\u001b[39m(labels_path)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines())\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(grace_hopper)\n",
      "File \u001b[0;32m~/.myenv/.myenv/lib/python3.11/site-packages/keras/src/utils/data_utils.py:264\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Downloads a file from a URL if it not already in the cache.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03mBy default the file at the url `origin` is downloaded to the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mare getting is the one you expect.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease specify the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m argument (URL of the file \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto download).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     cache_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Please specify the \"origin\" argument (URL of the file to download)."
     ]
    }
   ],
   "source": [
    "labels_path = tf.keras.utils.get_file()\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "\n",
    "plt.imshow(grace_hopper)\n",
    "plt.axis('off')\n",
    "pred_class_name = imagenet_labels[predicted_class]\n",
    "_  = plt.title(\"Prediction \" + pred_class_name.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3097414",
   "metadata": {},
   "source": [
    "## Part 2: Use a TensorFlow Hub models for the cats vs dogs dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd20fb1",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3659b91f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Split' object has no attribute 'subsplit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m splits \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubsplit\u001b[49m(weighted \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m      3\u001b[0m splits, info \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcats_vs_dogs\u001b[39m\u001b[38;5;124m'\u001b[39m, with_info  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, splits \u001b[38;5;241m=\u001b[39m splits, as_supervised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m (train_examples, val_examples) \u001b[38;5;241m=\u001b[39m splits\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Split' object has no attribute 'subsplit'"
     ]
    }
   ],
   "source": [
    "splits = tfds.Split.ALL.subsplit(weighted = (80, 20))\n",
    "\n",
    "splits, info = tfds.load('cats_vs_dogs', with_info  = True, splits = splits, as_supervised = True)\n",
    "\n",
    "(train_examples, val_examples) = splits\n",
    "\n",
    "num_examples = info.splits('train').num_examples\n",
    "num_classes = info.features('label').num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe2d56b",
   "metadata": {},
   "source": [
    "Images are not in the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68d5f085",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_examples\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m3\u001b[39m)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m Shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_examples' is not defined"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(train_examples.take(3)):\n",
    "    print(\"Image: {} Shape: {}\".format(i+1, image.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64591c11",
   "metadata": {},
   "source": [
    "#### Reformat all images to imagenet shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b5f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SHAPE, IMG_SHAPE)) / 255.0\n",
    "    return image, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_batches = train_examples.shuffle(train_example//4).map(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Virtual Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
