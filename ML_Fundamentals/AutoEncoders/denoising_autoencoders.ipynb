{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder\n",
    "\n",
    "Sticking with the MNIST dataset, let's add noise to our data and see if we can define and train an autoencoder to _de_-noise the images.\n",
    "\n",
    "<img src='notebook_ims/autoencoder_denoise.png' width=70%/>\n",
    "\n",
    "Let's get started by importing our libraries and getting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt | grep -v \"already\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After installing the dependencies you need to restart your kernel, then proceed with the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torch import nn\n",
    "import torchvision.models\n",
    "import torchvision.transforms as transforms\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from helpers import get_data_loaders\n",
    "from helpers import seed_all\n",
    "from helpers import anomaly_detection_display\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure repeatibility\n",
    "seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 48000 examples for training and 12000 for validation\n",
      "Using 10000 for testing\n"
     ]
    }
   ],
   "source": [
    "# This will get data loaders for the MNIST dataset for the train, validation\n",
    "# and test dataset\n",
    "data_loaders = get_data_loaders(batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(data_loaders['train'])\n",
    "images, labels = next(dataiter)\n",
    "images = images.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(images[0])\n",
    "\n",
    "fig, sub = plt.subplots(figsize = (2,2)) \n",
    "sub.imshow(img, cmap='gray')\n",
    "_ = sub.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Denoising\n",
    "\n",
    "As we've mentioned before, autoencoders like the ones you've built so far aren't too useful in practice. However, they can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1.\n",
    "\n",
    ">**We'll use noisy images as input and the original, clean images as targets.** \n",
    "\n",
    "Below is an example of some of the noisy images I generated and the associated, denoised images.\n",
    "\n",
    "<img src='notebook_ims/denoising.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will write a convolutional autoencoder. Given the difficulty of the task, you might want to add more layers than what we used in the previous exercises in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the NN architecture\n",
    "class ConvDenoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvDenoiser, self).__init__()\n",
    "        ## encoder layers ##\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, padding = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(8, 16, 3, padding = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )# YOUR CODE HERE\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 2, stride = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 16, 2, stride = 2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "\n",
    "            nn.Upsample(scale_factor = 2, mode = \"nearest\"),\n",
    "            nn.Conv2d(16, 8, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "            nn.Conv2d(8, 1, 3, padding = 1),\n",
    "            nn.Sigmoid()\n",
    "        )# YOUR CODE HERE\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            self.encoder,\n",
    "            self.decoder\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# initialize the NN\n",
    "model = ConvDenoiser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training\n",
    "\n",
    ">In this case, we are actually **adding some noise** to these images and we'll feed these `noisy_imgs` to our model. The model will produce reconstructed images based on the noisy input. But, we want it to produce _normal_ un-noisy images, and so, when we calculate the loss, we will still compare the reconstructed outputs to the original images!\n",
    "\n",
    "First let's specify the loss and the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "criterion = nn.MSELoss()# YOUR CODE HERE\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                        | 0/2400 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "# for adding noise to images\n",
    "noise_factor=0.5\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in tqdm(\n",
    "        desc=\"Training\", \n",
    "        total=len(data_loaders['train']), \n",
    "        iterable=data_loaders['train'],\n",
    "        ncols=80\n",
    "    ):\n",
    "        # _ stands in for labels, here\n",
    "        # no need to flatten images\n",
    "        images, _ = data\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "        \n",
    "        ## add random noise to the input images\n",
    "        noisy_imgs = images + noise_factor * torch.rand_like(images)\n",
    "        # Clip the images to be between 0 and 1\n",
    "        noisy_imgs = torch.clamp(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        ## forward pass: compute predicted outputs by passing *noisy* images to the model\n",
    "        outputs = model(noisy_imgs)\n",
    "        \n",
    "        # calculate the loss\n",
    "        # the \"target\" is still the original, not-noisy images\n",
    "        loss = criterion(outputs.flatten(), images.flatten())# YOUR CODE HERE\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(desc=\"Validating\", total=len(data_loaders['valid']), iterable=data_loaders['valid'],\n",
    "        ncols=80):\n",
    "            # _ stands in for labels, here\n",
    "            # no need to flatten images\n",
    "            images, _ = data\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "\n",
    "            ## add random noise to the input images\n",
    "            noisy_imgs = images + noise_factor * torch.rand_like(images)\n",
    "            # Clip the images to be between 0 and 1\n",
    "            noisy_imgs = torch.clamp(noisy_imgs, 0., 1.)\n",
    "            \n",
    "            ## forward pass: compute predicted outputs by passing *noisy* images to the model\n",
    "            outputs = model(noisy_imgs)\n",
    "            # calculate the loss\n",
    "            # the \"target\" is still the original, not-noisy images\n",
    "            loss = criterion(outputs, images)\n",
    "\n",
    "            # update running training loss\n",
    "            val_loss += loss.item()*images.size(0)\n",
    "    \n",
    "    # print avg training statistics\n",
    "    train_loss /= len(data_loaders['train'].dataset)\n",
    "    val_loss /= len(data_loaders['valid'].dataset)\n",
    "    print(\"Epoch: {} \\tTraining Loss: {:.6f}\\tValid Loss: {:.6f}\".format(epoch, train_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking out the results\n",
    "\n",
    "Here I'm adding noise to the test images and passing them through the autoencoder. It does a suprisingly great job of removing the noise, even though it's sometimes difficult to tell what the original number is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(data_loaders['test'])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# add noise to the test images\n",
    "noisy_imgs = images + 0.5 * torch.randn(*images.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "# get sample outputs\n",
    "output = model(noisy_imgs.cuda())\n",
    "# prep images for display\n",
    "noisy_imgs = noisy_imgs.numpy()\n",
    "\n",
    "# output is resized into a batch of iages\n",
    "output = output.view(20, 1, 28, 28)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().cpu().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for noisy_imgs, row in zip([noisy_imgs, output], axes):\n",
    "    for img, ax in zip(noisy_imgs, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
